{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgTRFUyLdiq00sSl15JT6E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriellfelipe7/Alura_EstatisticaComPython/blob/main/Ex2_SCC0634_2022_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercício 2 - SCC0634: Aplicações de Inteligência Artificial (2022/02)**\n",
        "- Nome: Gabriel Felipe Machado de Oliveira\n",
        "- N° USP: 11908695"
      ],
      "metadata": {
        "id": "RpteaZRTjt-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n2ZjEJrQ4RR",
        "outputId": "4a71645d-21fc-45e3-ca5e-ff5f1678b411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extração da Base"
      ],
      "metadata": {
        "id": "an4OydDmkFur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Através da bib Pandas, importaremos a base:"
      ],
      "metadata": {
        "id": "Mh4LSMsAs9Dz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iwYdEfXBjlPY",
        "outputId": "ee9c6d3e-2d4a-4048-e876-6c55c5b792f8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                    Text   Class\n",
              "0      articl galleri fan match report pictur site forum  Soccer\n",
              "1      bodi fan fox profit interest support citi demo...  Soccer\n",
              "2      club burnlei literatur team onlin form photograph  Soccer\n",
              "3      club histori inform honour wikipedia record to...  Soccer\n",
              "4      uefa uefa footbal footbal championship champio...  Soccer\n",
              "...                                                  ...     ...\n",
              "13495  press golden california staff bear releas berk...  Tennis\n",
              "13496  northwood staff game men tenni pictur seahawk ...  Tennis\n",
              "13497  player club england pro harri jason associ ten...  Tennis\n",
              "13498  stand individu inform men team tenni pictur re...  Tennis\n",
              "13499  north item aggi game new team tenni result upc...  Tennis\n",
              "\n",
              "[13500 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c58bfc73-7d25-4a40-9e9d-6b6805122a63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>articl galleri fan match report pictur site forum</td>\n",
              "      <td>Soccer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bodi fan fox profit interest support citi demo...</td>\n",
              "      <td>Soccer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>club burnlei literatur team onlin form photograph</td>\n",
              "      <td>Soccer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>club histori inform honour wikipedia record to...</td>\n",
              "      <td>Soccer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uefa uefa footbal footbal championship champio...</td>\n",
              "      <td>Soccer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13495</th>\n",
              "      <td>press golden california staff bear releas berk...</td>\n",
              "      <td>Tennis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13496</th>\n",
              "      <td>northwood staff game men tenni pictur seahawk ...</td>\n",
              "      <td>Tennis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13497</th>\n",
              "      <td>player club england pro harri jason associ ten...</td>\n",
              "      <td>Tennis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13498</th>\n",
              "      <td>stand individu inform men team tenni pictur re...</td>\n",
              "      <td>Tennis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13499</th>\n",
              "      <td>north item aggi game new team tenni result upc...</td>\n",
              "      <td>Tennis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13500 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c58bfc73-7d25-4a40-9e9d-6b6805122a63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c58bfc73-7d25-4a40-9e9d-6b6805122a63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c58bfc73-7d25-4a40-9e9d-6b6805122a63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "data = pd.read_csv('Dmoz-Sports.csv')\n",
        "display(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lista de Classes"
      ],
      "metadata": {
        "id": "Y8Wugx84Wg0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos verificar a lista de possíveis saídas da variável resposta:"
      ],
      "metadata": {
        "id": "eLaf2FpjtBnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "esportes = list(data['Class'].unique())\n",
        "esportes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlEUiXrFKshV",
        "outputId": "f79fea12-4a47-42c8-d4c0-733a77abe835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Soccer',\n",
              " 'Fencing',\n",
              " 'Equestrian',\n",
              " 'Wrestling',\n",
              " 'Volleyball',\n",
              " 'Winter_Sports',\n",
              " 'Basketball',\n",
              " 'Lacrosse',\n",
              " 'Football',\n",
              " 'Martial_Arts',\n",
              " 'Softball',\n",
              " 'Paintball',\n",
              " 'Flying_Discs',\n",
              " 'Cycling',\n",
              " 'Running',\n",
              " 'Baseball',\n",
              " 'Cricket',\n",
              " 'Gymnastics',\n",
              " 'Motorsports',\n",
              " 'Golf',\n",
              " 'Skating',\n",
              " 'Track_and_Field',\n",
              " 'Water_Sports',\n",
              " 'Bowling',\n",
              " 'Hockey',\n",
              " 'Strength_Sports',\n",
              " 'Tennis']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(esportes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqbf2bmFK9op",
        "outputId": "99f14f7f-5226-4e86-ba49-d7317deff6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temos 27 possíveis saídas para os dados."
      ],
      "metadata": {
        "id": "QRNIuIXqLCZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separando base de treino e teste"
      ],
      "metadata": {
        "id": "McvbkxBr9jt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(data, test_size=0.33)"
      ],
      "metadata": {
        "id": "wd02aaGkWxG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificando os dados:"
      ],
      "metadata": {
        "id": "rr5yp1z1W__H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNtnz1bKXE54",
        "outputId": "7302e49b-fbc4-43cd-9ea8-aa4bbeb8b807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4455, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p1_ArDfXJjn",
        "outputId": "125c7be2-26ae-4aaa-a0c9-99a7adb14a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9045, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métodos de apoio"
      ],
      "metadata": {
        "id": "37HQrW9oQBOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text,stop_words):\n",
        "  \n",
        "  # tudo para caixa baixa\n",
        "  s = str(text).lower() \n",
        "\n",
        "  tokens = word_tokenize(s)\n",
        "\n",
        "  # remove stopwords, dígitos, caracteres especiais e pontuações\n",
        "  v = [word for word in tokens if not word in stop_words and word.isalnum() and not word.isdigit()]\n",
        "\n",
        "  return v\n",
        "\n",
        "def stemming(tokens,stemmer):\n",
        "  tokens_stems = [stemmer.stem(word) for word in tokens]\n",
        "  return tokens_stems\n",
        "\n",
        "def meu_tokenizador(doc, stop_words=nltk.corpus.stopwords.words('english'), stemmer=PorterStemmer()):\n",
        "  tokens = remove_stopwords(doc,stop_words)\n",
        "  return stemming(tokens,stemmer)"
      ],
      "metadata": {
        "id": "IPcW0CV7QDRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pré-processamento e Treinamento\n",
        "Utilizamos o o modelo de transformação geral \"distiluse-base-multilingual-cased-v1\""
      ],
      "metadata": {
        "id": "ZE26AZsUFiJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentence_transformers\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHLNG0gAFldC",
        "outputId": "427cf8d9-0d88-4fd2-b1c8-d8827d20f97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.23.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.97)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.1.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence_transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos carregar o modelo\n",
        "sbert  = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
      ],
      "metadata": {
        "id": "Axyp4LH5F28f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separando as palavras das classes e pre ptrocessão o encoder\n",
        "\n",
        "\n",
        "documents = np.array(df_train['Text'].to_list())\n",
        "labels = np.array(df_train['Class'].to_list())\n",
        "\n",
        "\n",
        "# vamos usar validação cruzada estratificada com 5 folds\n",
        "skf = StratifiedKFold(n_splits=2, random_state=42, shuffle=True)\n",
        "\n",
        "for k in [5,7]:\n",
        "  fold = 1\n",
        "  L_acc = []\n",
        "  for train_index, test_index in skf.split(documents, labels):\n",
        "\n",
        "      # separando os documentos de treino e teste considerando cada fold.\n",
        "      documents_train, documents_test = documents[train_index], documents[test_index]\n",
        "      labels_train, labels_test = labels[train_index], labels[test_index]\n",
        "\n",
        "      # preprocessamento\n",
        "      sbert  = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
        "      X_train2 = sbert.encode(documents_train)\n",
        "      X_test2 = sbert.encode(documents_test)\n",
        "\n",
        "      # classificador 1NN do Cenario 2\n",
        "      clf2 = KNeighborsClassifier(n_neighbors=k,metric='cosine')\n",
        "      clf2.fit(X_train2,labels_train)\n",
        "\n",
        "      # imprimindo resultados\n",
        "      print('Fold =',fold,' k=',k)\n",
        "      acc = clf2.score(X_test2, labels_test)\n",
        "      print('\\tACC usando TF-IDF =',acc)\n",
        "\n",
        "      L_acc.append(acc)\n",
        "\n",
        "      fold += 1\n",
        "  print('acc k=',k,np.mean(L_acc))\n",
        "  print('=======')"
      ],
      "metadata": {
        "id": "DQUZ_dZjYenh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f6385b-d1c8-476a-f3e7-d242038ce403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold = 1  k= 5\n",
            "\tACC usando TF-IDF = 0.6933451249170904\n",
            "Fold = 2  k= 5\n",
            "\tACC usando TF-IDF = 0.7043343653250774\n",
            "acc k= 5 0.6988397451210839\n",
            "=======\n",
            "Fold = 1  k= 7\n",
            "\tACC usando TF-IDF = 0.698872429803228\n",
            "Fold = 2  k= 7\n",
            "\tACC usando TF-IDF = 0.7091994692613888\n",
            "acc k= 7 0.7040359495323083\n",
            "=======\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ERRATA: Perceba que foi utilizado o outro modo de codificação, e não TF-IDF, por conta da demora de execução, foi impossível a executar novamente a célula."
      ],
      "metadata": {
        "id": "bVXGZGFll90_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decisão"
      ],
      "metadata": {
        "id": "x-aKE9vBepoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos k = 7"
      ],
      "metadata": {
        "id": "vR3LNFckdlva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k=7\n",
        "\n",
        "# separando os documentos de treino e teste considerando cada fold.\n",
        "\n",
        "# preprocessamento (ponderação TF-IDF)\n",
        "sbert  = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
        "X_train2 = sbert.encode(df_train['Text'].to_list())\n",
        "X_test2 = sbert.encode(df_test['Text'].to_list())\n",
        "\n",
        "# classificador 1NN do Cenario 2\n",
        "clf2 = KNeighborsClassifier(n_neighbors=k,metric='cosine')\n",
        "clf2.fit(X_train2,df_train['Class'].to_list())\n",
        "\n",
        "# imprimindo resultados\n",
        "acc = clf2.score(X_test2, df_test['Class'].to_list())\n",
        "print('\\tACC usando Sentence Transformer =',acc)"
      ],
      "metadata": {
        "id": "YZlkAmr6eqe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baf0e5fc-931c-4c96-fa43-758aca79f590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tACC usando Sentence Transformer = 0.7441077441077442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando kFoldValidation e a Sentence Transformer, alcançamos uma acurácia (medida cosseno) de 74.41%."
      ],
      "metadata": {
        "id": "gBTXuYopnOpI"
      }
    }
  ]
}